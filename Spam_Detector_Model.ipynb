import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

## Predictive Model for SMS Spam Detection

# This Jupyter Notebook demonstrates the implementation of a machine learning model using scikit-learn to classify SMS messages as either "ham" (legitimate) or "spam".

### 1. Dataset Creation

# For this demonstration, we'll create a small, representative dataset directly within the notebook. In a real-world scenario, you would typically load a larger dataset from a CSV file (e.g., the SMS Spam Collection Dataset).

data = {
    'text': [
        "Go until jurong point, crazy.. Available only in bugis n great world la e buffet...",
        "Ok lar... Joking wif u oni...",
        "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply.",
        "U dun say so early hor... U c already then say...",
        "Nah I don't think he goes to usf, he lives around here though",
        "SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days/wk. T&C's apply",
        "I HAVE A DATE ON SUNDAY WITH WILL!!",
        "XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGITEIPEK",
        "Oh k...i'm watching here:)",
        "WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.",
        "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030",
        "I'm gonna be in miami. I'll be home tomorrow evening.",
        "URGENT! Your mobile number has been awarded a £2000 prize. Call 09066661234 now to claim.",
        "Hey, are we still on for dinner tonight?",
        "Congratulations! You've won a brand new car. Text CLAIM to 45678 for details."
    ],
    'label': [
        'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'spam', 'ham', 'spam', 'ham', 'spam'
    ]
}
df = pd.DataFrame(data)

print("Dataset Head:")
print(df.head())
print("\nLabel Distribution:")
print(df['label'].value_counts())

### 2. Data Preprocessing

# We'll convert the text into numerical features using `TfidfVectorizer` and then split the data into training and testing sets.

# Convert labels to numerical format (0 for ham, 1 for spam)
df['label_encoded'] = df['label'].map({'ham': 0, 'spam': 1})

# Separate features (X) and target (y)
X = df['text']
y = df['label_encoded']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

print(f"\nTraining set size: {len(X_train)}")
print(f"Testing set size: {len(X_test)}")

# Initialize TF-IDF Vectorizer
tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)

# Fit and transform the training data
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)

# Transform the test data
X_test_tfidf = tfidf_vectorizer.transform(X_test)

print(f"\nShape of X_train_tfidf: {X_train_tfidf.shape}")
print(f"Shape of X_test_tfidf: {X_test_tfidf.shape}")

### 3. Model Selection and Training

# We'll use `Multinomial Naive Bayes`, a common and effective classifier for text classification tasks.

# Initialize the Multinomial Naive Bayes classifier
model = MultinomialNB()

# Train the model
model.fit(X_train_tfidf, y_train)

print("\nModel training complete.")

### 4. Prediction

# Now, we'll use the trained model to make predictions on the unseen test set.

# Make predictions on the test set
y_pred = model.predict(X_test_tfidf)

print("\nPredictions on test set:")
print(y_pred)

### 5. Model Evaluation

# We'll evaluate the model's performance using standard classification metrics and a confusion matrix.

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"\nModel Evaluation:")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(cm)

# Visualize Confusion Matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Ham (Predicted)', 'Spam (Predicted)'],
            yticklabels=['Ham (Actual)', 'Spam (Actual)'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for SMS Spam Detection')
plt.show()

### 6. Example Prediction

# Let's see how our trained model performs on some new, arbitrary SMS messages.

# Example new messages
new_sms_messages = [
    "Congratulations! You've won a £1000 gift card. Claim now at example.com/prize",
    "Hey, what are you doing this evening?",
    "URGENT! Your account has been suspended. Click this link to reactivate: maliciouslink.com",
    "Your package has been delayed. Track it here: tinyurl.com/track",
    "Just calling to confirm our meeting for tomorrow at 10 AM."
]

# Transform new messages using the *trained* TF-IDF vectorizer
new_sms_messages_tfidf = tfidf_vectorizer.transform(new_sms_messages)

# Predict
new_predictions = model.predict(new_sms_messages_tfidf)

# Map numerical predictions back to labels
label_map = {0: 'ham', 1: 'spam'}
predicted_labels = [label_map[pred] for pred in new_predictions]

print("\nPredictions for new SMS messages:")
for i, message in enumerate(new_sms_messages):
    print(f"Message: '{message}'\nPredicted as: {predicted_labels[i]}\n")
